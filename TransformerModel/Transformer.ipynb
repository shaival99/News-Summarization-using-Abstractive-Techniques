{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDBrP3rZ0YXi",
        "outputId": "e3b6b0bd-e444-43a7-eee7-680594e337f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages needed and Importing Libraries"
      ],
      "metadata": {
        "id": "nM115Ldw0S2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl  --quiet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T15:24:35.025365Z",
          "iopub.execute_input": "2022-04-18T15:24:35.025718Z",
          "iopub.status.idle": "2022-04-18T15:24:40.543738Z",
          "shell.execute_reply.started": "2022-04-18T15:24:35.025687Z",
          "shell.execute_reply": "2022-04-18T15:24:40.542722Z"
        },
        "trusted": true,
        "id": "RMo4Kpaf0S2a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FKswjxHtoPs",
        "outputId": "98c1c88c-c2bf-4065-94a9-5e6bb0b78d57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.0.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "metric = load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "cj234QOWtqge"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T15:24:43.428633Z",
          "iopub.execute_input": "2022-04-18T15:24:43.428953Z",
          "iopub.status.idle": "2022-04-18T15:24:43.435182Z",
          "shell.execute_reply.started": "2022-04-18T15:24:43.428917Z",
          "shell.execute_reply": "2022-04-18T15:24:43.434218Z"
        },
        "trusted": true,
        "id": "khoAv2ei0S2a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_LEN = 1000\n",
        "DECODER_LEN = 90\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 60000 #This value should be equal to more than the training set, which is around 58000 for our case"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T15:24:46.581667Z",
          "iopub.execute_input": "2022-04-18T15:24:46.581992Z",
          "iopub.status.idle": "2022-04-18T15:24:46.585937Z",
          "shell.execute_reply.started": "2022-04-18T15:24:46.58196Z",
          "shell.execute_reply": "2022-04-18T15:24:46.585117Z"
        },
        "trusted": true,
        "id": "gjvolKFq0S2c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "After creating the dataframe we apply Start of Sentence(<SOS>) and End of Sentence(<EOS>) tokens. \n",
        "These sentences are then tokenized and padded to fix length."
      ],
      "metadata": {
        "id": "r99C75Wz0S2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news = pd.read_csv(\"/content/drive/MyDrive/DL Project/train.csv\")\n",
        "news = news.sample(frac=0.2)\n",
        "news.drop(['id'], axis=1, inplace=True)\n",
        "news.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:00:58.517146Z",
          "iopub.execute_input": "2022-04-18T16:00:58.517509Z",
          "iopub.status.idle": "2022-04-18T16:01:09.446906Z",
          "shell.execute_reply.started": "2022-04-18T16:00:58.517476Z",
          "shell.execute_reply": "2022-04-18T16:01:09.44608Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0lJdW1d-0S2d",
        "outputId": "5522c294-e8b4-41f3-b0e1-87c71fc06e0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  article  \\\n",
              "125488  (Rolling Stone) -- For Neil Young, the Sixties...   \n",
              "60448   By . Daily Mail Reporter . PUBLISHED: . 10:27 ...   \n",
              "161211  A manhunt has been launched to find a pregnant...   \n",
              "220865  Washington (CNN) -- Anticipating possible poli...   \n",
              "149583  By . Paul Thompson . PUBLISHED: . 11:21 EST, 7...   \n",
              "\n",
              "                                               highlights  \n",
              "125488  Psychedelic Pill is Young's second album of 20...  \n",
              "60448   Tennis hero thwarted in bid for new course in ...  \n",
              "161211  Aubrey Andrews, 20, 'drove to a friend's house...  \n",
              "220865  Texas senator believes cuts may not be as bad ...  \n",
              "149583  Kayla Garcia, 4, died on May 9 after she was a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04f0406e-3c62-4a57-9735-f1caa735907b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>125488</th>\n",
              "      <td>(Rolling Stone) -- For Neil Young, the Sixties...</td>\n",
              "      <td>Psychedelic Pill is Young's second album of 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60448</th>\n",
              "      <td>By . Daily Mail Reporter . PUBLISHED: . 10:27 ...</td>\n",
              "      <td>Tennis hero thwarted in bid for new course in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161211</th>\n",
              "      <td>A manhunt has been launched to find a pregnant...</td>\n",
              "      <td>Aubrey Andrews, 20, 'drove to a friend's house...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220865</th>\n",
              "      <td>Washington (CNN) -- Anticipating possible poli...</td>\n",
              "      <td>Texas senator believes cuts may not be as bad ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149583</th>\n",
              "      <td>By . Paul Thompson . PUBLISHED: . 11:21 EST, 7...</td>\n",
              "      <td>Kayla Garcia, 4, died on May 9 after she was a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04f0406e-3c62-4a57-9735-f1caa735907b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04f0406e-3c62-4a57-9735-f1caa735907b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04f0406e-3c62-4a57-9735-f1caa735907b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:20.346006Z",
          "iopub.execute_input": "2022-04-18T16:14:20.346351Z",
          "iopub.status.idle": "2022-04-18T16:14:20.351941Z",
          "shell.execute_reply.started": "2022-04-18T16:14:20.346317Z",
          "shell.execute_reply": "2022-04-18T16:14:20.351017Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jY65JSb0S2e",
        "outputId": "c00c3af9-3e90-48da-9643-bca08d4854bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57423, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article = news['article']\n",
        "summary = news['highlights']\n",
        "article = article.apply(lambda x: '<SOS> ' + x + ' <EOS>')\n",
        "summary = summary.apply(lambda x: '<SOS> ' + x + ' <EOS>')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:01:19.688995Z",
          "iopub.execute_input": "2022-04-18T16:01:19.68933Z",
          "iopub.status.idle": "2022-04-18T16:01:20.025837Z",
          "shell.execute_reply.started": "2022-04-18T16:01:19.689298Z",
          "shell.execute_reply": "2022-04-18T16:01:20.024986Z"
        },
        "trusted": true,
        "id": "Y7envpF50S2e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = re.sub(r\"&.[1-9]+;\",\" \",text)\n",
        "    return text\n",
        "article = article.apply(lambda x: preprocess(x))\n",
        "summary = summary.apply(lambda x: preprocess(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:01:22.165668Z",
          "iopub.execute_input": "2022-04-18T16:01:22.165974Z",
          "iopub.status.idle": "2022-04-18T16:01:22.635631Z",
          "shell.execute_reply.started": "2022-04-18T16:01:22.165944Z",
          "shell.execute_reply": "2022-04-18T16:01:22.634792Z"
        },
        "trusted": true,
        "id": "z6mVkTlP0S2f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "article_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "article_tokenizer.fit_on_texts(article)\n",
        "summary_tokenizer.fit_on_texts(summary)\n",
        "inputs = article_tokenizer.texts_to_sequences(article)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:01:25.411382Z",
          "iopub.execute_input": "2022-04-18T16:01:25.4117Z",
          "iopub.status.idle": "2022-04-18T16:03:26.338306Z",
          "shell.execute_reply.started": "2022-04-18T16:01:25.41167Z",
          "shell.execute_reply": "2022-04-18T16:03:26.337416Z"
        },
        "trusted": true,
        "id": "zioOqkmZ0S2g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vocabulary of our encoder and decoder"
      ],
      "metadata": {
        "id": "lUFfdZI0_Amd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_VOCAB = len(article_tokenizer.word_index) + 1\n",
        "DECODER_VOCAB = len(summary_tokenizer.word_index) + 1\n",
        "print(ENCODER_VOCAB, DECODER_VOCAB)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:03:58.585997Z",
          "iopub.execute_input": "2022-04-18T16:03:58.586347Z",
          "iopub.status.idle": "2022-04-18T16:03:58.591777Z",
          "shell.execute_reply.started": "2022-04-18T16:03:58.586314Z",
          "shell.execute_reply": "2022-04-18T16:03:58.590723Z"
        },
        "trusted": true,
        "id": "4ODXThm10S2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67fcae8a-681a-4480-c1d5-580dfe77f64b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331846 100742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### "
      ],
      "metadata": {
        "id": "x4BaWVtE_Fxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\n",
        "inputs = tf.cast(inputs, dtype=tf.int64)\n",
        "targets = tf.cast(targets, dtype=tf.int64)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:04:30.482628Z",
          "iopub.execute_input": "2022-04-18T16:04:30.482933Z",
          "iopub.status.idle": "2022-04-18T16:04:45.845899Z",
          "shell.execute_reply.started": "2022-04-18T16:04:30.482903Z",
          "shell.execute_reply": "2022-04-18T16:04:45.844919Z"
        },
        "trusted": true,
        "id": "LUsjTvKK0S2i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:04:56.339727Z",
          "iopub.execute_input": "2022-04-18T16:04:56.340029Z",
          "iopub.status.idle": "2022-04-18T16:04:56.892821Z",
          "shell.execute_reply.started": "2022-04-18T16:04:56.34Z",
          "shell.execute_reply": "2022-04-18T16:04:56.891974Z"
        },
        "trusted": true,
        "id": "d0rCLqpq0S2i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Model\n",
        "\n",
        "The next several blocks of code contain the vanilla Transformer model.\n",
        "\n",
        "If you want to know about what they are and how they work I suggest this video: https://www.youtube.com/watch?v=4Bdc55j80l8\n",
        "\n",
        "It does an excellent job of giving an overview about them and helped me in understanding them."
      ],
      "metadata": {
        "id": "IuIqp8Li0S2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:29.054073Z",
          "iopub.execute_input": "2022-04-18T16:14:29.054409Z",
          "iopub.status.idle": "2022-04-18T16:14:29.066612Z",
          "shell.execute_reply.started": "2022-04-18T16:14:29.054377Z",
          "shell.execute_reply": "2022-04-18T16:14:29.065698Z"
        },
        "trusted": true,
        "id": "y3vDlqeM0S2i"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        \n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "            \n",
        "        return output, attention_weights\n",
        "    \n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:30.05906Z",
          "iopub.execute_input": "2022-04-18T16:14:30.05941Z",
          "iopub.status.idle": "2022-04-18T16:14:30.07051Z",
          "shell.execute_reply.started": "2022-04-18T16:14:30.059375Z",
          "shell.execute_reply": "2022-04-18T16:14:30.06963Z"
        },
        "trusted": true,
        "id": "3FXaCuOD0S2j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:30.692961Z",
          "iopub.execute_input": "2022-04-18T16:14:30.69329Z",
          "iopub.status.idle": "2022-04-18T16:14:30.701169Z",
          "shell.execute_reply.started": "2022-04-18T16:14:30.693259Z",
          "shell.execute_reply": "2022-04-18T16:14:30.700272Z"
        },
        "trusted": true,
        "id": "GLG5uINW0S2k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:31.349405Z",
          "iopub.execute_input": "2022-04-18T16:14:31.349715Z",
          "iopub.status.idle": "2022-04-18T16:14:31.359319Z",
          "shell.execute_reply.started": "2022-04-18T16:14:31.349686Z",
          "shell.execute_reply": "2022-04-18T16:14:31.358258Z"
        },
        "trusted": true,
        "id": "Mk4fBOLR0S2l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "        return x\n",
        "    \n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "        \n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "        return x, attention_weights\n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:31.975409Z",
          "iopub.execute_input": "2022-04-18T16:14:31.975731Z",
          "iopub.status.idle": "2022-04-18T16:14:31.990616Z",
          "shell.execute_reply.started": "2022-04-18T16:14:31.975698Z",
          "shell.execute_reply": "2022-04-18T16:14:31.989283Z"
        },
        "trusted": true,
        "id": "OonzhDmr0S2l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:32.562814Z",
          "iopub.execute_input": "2022-04-18T16:14:32.563136Z",
          "iopub.status.idle": "2022-04-18T16:14:32.570437Z",
          "shell.execute_reply.started": "2022-04-18T16:14:32.563104Z",
          "shell.execute_reply": "2022-04-18T16:14:32.569422Z"
        },
        "trusted": true,
        "id": "V-iZbFMy0S2l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 4\n",
        "dropout_rate = 0.2\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:22.511999Z",
          "iopub.execute_input": "2022-04-18T21:13:22.51236Z",
          "iopub.status.idle": "2022-04-18T21:13:22.51764Z",
          "shell.execute_reply.started": "2022-04-18T21:13:22.512327Z",
          "shell.execute_reply": "2022-04-18T21:13:22.515666Z"
        },
        "trusted": true,
        "id": "tzLrp9fT0S2m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Learning Rate"
      ],
      "metadata": {
        "id": "47TqR1e10S2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:35.294707Z",
          "iopub.execute_input": "2022-04-18T21:13:35.295016Z",
          "iopub.status.idle": "2022-04-18T21:13:35.301191Z",
          "shell.execute_reply.started": "2022-04-18T21:13:35.294986Z",
          "shell.execute_reply": "2022-04-18T21:13:35.300053Z"
        },
        "trusted": true,
        "id": "p0fEDMRn0S2m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:35.955005Z",
          "iopub.execute_input": "2022-04-18T21:13:35.955378Z",
          "iopub.status.idle": "2022-04-18T21:13:35.960798Z",
          "shell.execute_reply.started": "2022-04-18T21:13:35.955346Z",
          "shell.execute_reply": "2022-04-18T21:13:35.95995Z"
        },
        "trusted": true,
        "id": "XUicG44r0S2n"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:36.730048Z",
          "iopub.execute_input": "2022-04-18T21:13:36.730401Z",
          "iopub.status.idle": "2022-04-18T21:13:36.903049Z",
          "shell.execute_reply.started": "2022-04-18T21:13:36.73037Z",
          "shell.execute_reply": "2022-04-18T21:13:36.901924Z"
        },
        "trusted": true,
        "id": "jrjb6Tza0S2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "700dc7cd-82b1-482a-fc12-2816ddff33bd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Loss and Accuracy"
      ],
      "metadata": {
        "id": "K2YNbGbA0S2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:38.099689Z",
          "iopub.execute_input": "2022-04-18T21:13:38.100014Z",
          "iopub.status.idle": "2022-04-18T21:13:38.108656Z",
          "shell.execute_reply.started": "2022-04-18T21:13:38.099981Z",
          "shell.execute_reply": "2022-04-18T21:13:38.107394Z"
        },
        "trusted": true,
        "id": "8DYtfybT0S2n"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:43.657543Z",
          "iopub.execute_input": "2022-04-18T21:13:43.657853Z",
          "iopub.status.idle": "2022-04-18T21:13:43.675333Z",
          "shell.execute_reply.started": "2022-04-18T21:13:43.657824Z",
          "shell.execute_reply": "2022-04-18T21:13:43.674614Z"
        },
        "trusted": true,
        "id": "dX5Zwhu30S2o"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=ENCODER_VOCAB,\n",
        "    target_vocab_size=DECODER_VOCAB,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:44.626431Z",
          "iopub.execute_input": "2022-04-18T21:13:44.62684Z",
          "iopub.status.idle": "2022-04-18T21:13:45.366521Z",
          "shell.execute_reply.started": "2022-04-18T21:13:44.6268Z",
          "shell.execute_reply": "2022-04-18T21:13:45.365483Z"
        },
        "trusted": true,
        "id": "hYkEXLlg0S2o"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:45.792139Z",
          "iopub.execute_input": "2022-04-18T21:13:45.79255Z",
          "iopub.status.idle": "2022-04-18T21:13:45.798183Z",
          "shell.execute_reply.started": "2022-04-18T21:13:45.792511Z",
          "shell.execute_reply": "2022-04-18T21:13:45.797153Z"
        },
        "trusted": true,
        "id": "rkwJ3g2E0S2o"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/DL Project\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:46.898611Z",
          "iopub.execute_input": "2022-04-18T21:13:46.89893Z",
          "iopub.status.idle": "2022-04-18T21:13:46.922022Z",
          "shell.execute_reply.started": "2022-04-18T21:13:46.898899Z",
          "shell.execute_reply": "2022-04-18T21:13:46.921249Z"
        },
        "trusted": true,
        "id": "lSQnsRdY0S2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41002959-f29f-4c7e-cf0d-9298cbec18fd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, \n",
        "            True, \n",
        "            enc_padding_mask, \n",
        "            combined_mask, \n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:47.919065Z",
          "iopub.execute_input": "2022-04-18T21:13:47.919419Z",
          "iopub.status.idle": "2022-04-18T21:13:48.171061Z",
          "shell.execute_reply.started": "2022-04-18T21:13:47.919387Z",
          "shell.execute_reply": "2022-04-18T21:13:48.170084Z"
        },
        "trusted": true,
        "id": "D_diTdOx0S2t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "u8C5EKDv0S2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "    \n",
        "        if batch % 100 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "      \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "   \n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:51.107977Z",
          "iopub.execute_input": "2022-04-18T21:13:51.10835Z"
        },
        "trusted": true,
        "id": "PGEgyJ6H0S2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579184f9-2a8b-4fd7-f087-99214c9003ef"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 5.8872 Accuracy 0.1559\n",
            "Epoch 1 Batch 100 Loss 5.9928 Accuracy 0.1560\n",
            "Epoch 1 Batch 200 Loss 6.0031 Accuracy 0.1561\n",
            "Epoch 1 Batch 300 Loss 6.0126 Accuracy 0.1562\n",
            "Epoch 1 Batch 400 Loss 6.0146 Accuracy 0.1563\n",
            "Epoch 1 Batch 500 Loss 6.0172 Accuracy 0.1564\n",
            "Epoch 1 Batch 600 Loss 6.0146 Accuracy 0.1565\n",
            "Epoch 1 Batch 700 Loss 6.0202 Accuracy 0.1566\n",
            "Epoch 1 Batch 800 Loss 6.0231 Accuracy 0.1567\n",
            "Epoch 1 Batch 900 Loss 6.0268 Accuracy 0.1568\n",
            "Epoch 1 Batch 1000 Loss 6.0360 Accuracy 0.1569\n",
            "Epoch 1 Batch 1100 Loss 6.0398 Accuracy 0.1570\n",
            "Epoch 1 Batch 1200 Loss 6.0445 Accuracy 0.1571\n",
            "Epoch 1 Batch 1300 Loss 6.0453 Accuracy 0.1572\n",
            "Epoch 1 Batch 1400 Loss 6.0491 Accuracy 0.1573\n",
            "Epoch 1 Batch 1500 Loss 6.0514 Accuracy 0.1574\n",
            "Epoch 1 Batch 1600 Loss 6.0556 Accuracy 0.1575\n",
            "Epoch 1 Batch 1700 Loss 6.0576 Accuracy 0.1575\n",
            "Epoch 1 Batch 1800 Loss 6.0606 Accuracy 0.1576\n",
            "Epoch 1 Batch 1900 Loss 6.0622 Accuracy 0.1577\n",
            "Epoch 1 Batch 2000 Loss 6.0643 Accuracy 0.1578\n",
            "Epoch 1 Batch 2100 Loss 6.0684 Accuracy 0.1579\n",
            "Epoch 1 Batch 2200 Loss 6.0701 Accuracy 0.1580\n",
            "Epoch 1 Batch 2300 Loss 6.0738 Accuracy 0.1581\n",
            "Epoch 1 Batch 2400 Loss 6.0765 Accuracy 0.1582\n",
            "Epoch 1 Batch 2500 Loss 6.0804 Accuracy 0.1583\n",
            "Epoch 1 Batch 2600 Loss 6.0808 Accuracy 0.1583\n",
            "Epoch 1 Batch 2700 Loss 6.0829 Accuracy 0.1584\n",
            "Epoch 1 Batch 2800 Loss 6.0851 Accuracy 0.1585\n",
            "Epoch 1 Batch 2900 Loss 6.0874 Accuracy 0.1586\n",
            "Epoch 1 Batch 3000 Loss 6.0880 Accuracy 0.1587\n",
            "Epoch 1 Batch 3100 Loss 6.0886 Accuracy 0.1588\n",
            "Epoch 1 Batch 3200 Loss 6.0910 Accuracy 0.1588\n",
            "Epoch 1 Batch 3300 Loss 6.0924 Accuracy 0.1589\n",
            "Epoch 1 Batch 3400 Loss 6.0933 Accuracy 0.1590\n",
            "Epoch 1 Batch 3500 Loss 6.0950 Accuracy 0.1591\n",
            "Epoch 1 Loss 6.0962 Accuracy 0.1592\n",
            "Time taken for 1 epoch: 1458.4327101707458 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 5.9397 Accuracy 0.1592\n",
            "Epoch 2 Batch 100 Loss 5.9540 Accuracy 0.1593\n",
            "Epoch 2 Batch 200 Loss 5.9666 Accuracy 0.1594\n",
            "Epoch 2 Batch 300 Loss 5.9747 Accuracy 0.1595\n",
            "Epoch 2 Batch 400 Loss 5.9781 Accuracy 0.1596\n",
            "Epoch 2 Batch 500 Loss 5.9860 Accuracy 0.1596\n",
            "Epoch 2 Batch 600 Loss 5.9818 Accuracy 0.1597\n",
            "Epoch 2 Batch 700 Loss 5.9858 Accuracy 0.1598\n",
            "Epoch 2 Batch 800 Loss 5.9912 Accuracy 0.1599\n",
            "Epoch 2 Batch 900 Loss 5.9964 Accuracy 0.1600\n",
            "Epoch 2 Batch 1000 Loss 5.9994 Accuracy 0.1601\n",
            "Epoch 2 Batch 1100 Loss 6.0040 Accuracy 0.1602\n",
            "Epoch 2 Batch 1200 Loss 6.0095 Accuracy 0.1603\n",
            "Epoch 2 Batch 1300 Loss 6.0141 Accuracy 0.1604\n",
            "Epoch 2 Batch 1400 Loss 6.0175 Accuracy 0.1605\n",
            "Epoch 2 Batch 1500 Loss 6.0228 Accuracy 0.1605\n",
            "Epoch 2 Batch 1600 Loss 6.0259 Accuracy 0.1606\n",
            "Epoch 2 Batch 1700 Loss 6.0299 Accuracy 0.1607\n",
            "Epoch 2 Batch 1800 Loss 6.0323 Accuracy 0.1608\n",
            "Epoch 2 Batch 1900 Loss 6.0362 Accuracy 0.1609\n",
            "Epoch 2 Batch 2000 Loss 6.0383 Accuracy 0.1610\n",
            "Epoch 2 Batch 2100 Loss 6.0407 Accuracy 0.1611\n",
            "Epoch 2 Batch 2200 Loss 6.0431 Accuracy 0.1611\n",
            "Epoch 2 Batch 2300 Loss 6.0438 Accuracy 0.1612\n",
            "Epoch 2 Batch 2400 Loss 6.0466 Accuracy 0.1613\n",
            "Epoch 2 Batch 2500 Loss 6.0477 Accuracy 0.1614\n",
            "Epoch 2 Batch 2600 Loss 6.0494 Accuracy 0.1615\n",
            "Epoch 2 Batch 2700 Loss 6.0519 Accuracy 0.1615\n",
            "Epoch 2 Batch 2800 Loss 6.0537 Accuracy 0.1616\n",
            "Epoch 2 Batch 2900 Loss 6.0555 Accuracy 0.1617\n",
            "Epoch 2 Batch 3000 Loss 6.0575 Accuracy 0.1618\n",
            "Epoch 2 Batch 3100 Loss 6.0599 Accuracy 0.1618\n",
            "Epoch 2 Batch 3200 Loss 6.0630 Accuracy 0.1619\n",
            "Epoch 2 Batch 3300 Loss 6.0643 Accuracy 0.1620\n",
            "Epoch 2 Batch 3400 Loss 6.0660 Accuracy 0.1621\n",
            "Epoch 2 Batch 3500 Loss 6.0682 Accuracy 0.1621\n",
            "Epoch 2 Loss 6.0701 Accuracy 0.1622\n",
            "Time taken for 1 epoch: 1459.9353864192963 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 6.1175 Accuracy 0.1622\n",
            "Epoch 3 Batch 100 Loss 5.9799 Accuracy 0.1623\n",
            "Epoch 3 Batch 200 Loss 5.9707 Accuracy 0.1624\n",
            "Epoch 3 Batch 300 Loss 5.9753 Accuracy 0.1625\n",
            "Epoch 3 Batch 400 Loss 5.9733 Accuracy 0.1626\n",
            "Epoch 3 Batch 500 Loss 5.9763 Accuracy 0.1626\n",
            "Epoch 3 Batch 600 Loss 5.9791 Accuracy 0.1627\n",
            "Epoch 3 Batch 700 Loss 5.9768 Accuracy 0.1628\n",
            "Epoch 3 Batch 800 Loss 5.9772 Accuracy 0.1629\n",
            "Epoch 3 Batch 900 Loss 5.9814 Accuracy 0.1630\n",
            "Epoch 3 Batch 1000 Loss 5.9876 Accuracy 0.1631\n",
            "Epoch 3 Batch 1100 Loss 5.9926 Accuracy 0.1631\n",
            "Epoch 3 Batch 1200 Loss 5.9978 Accuracy 0.1632\n",
            "Epoch 3 Batch 1300 Loss 5.9989 Accuracy 0.1633\n",
            "Epoch 3 Batch 1400 Loss 6.0028 Accuracy 0.1634\n",
            "Epoch 3 Batch 1500 Loss 6.0051 Accuracy 0.1634\n",
            "Epoch 3 Batch 1600 Loss 6.0084 Accuracy 0.1635\n",
            "Epoch 3 Batch 1700 Loss 6.0106 Accuracy 0.1636\n",
            "Epoch 3 Batch 1800 Loss 6.0149 Accuracy 0.1637\n",
            "Epoch 3 Batch 1900 Loss 6.0184 Accuracy 0.1637\n",
            "Epoch 3 Batch 2000 Loss 6.0203 Accuracy 0.1638\n",
            "Epoch 3 Batch 2100 Loss 6.0215 Accuracy 0.1639\n",
            "Epoch 3 Batch 2200 Loss 6.0238 Accuracy 0.1640\n",
            "Epoch 3 Batch 2300 Loss 6.0267 Accuracy 0.1640\n",
            "Epoch 3 Batch 2400 Loss 6.0289 Accuracy 0.1641\n",
            "Epoch 3 Batch 2500 Loss 6.0305 Accuracy 0.1642\n",
            "Epoch 3 Batch 2600 Loss 6.0326 Accuracy 0.1643\n",
            "Epoch 3 Batch 2700 Loss 6.0352 Accuracy 0.1643\n",
            "Epoch 3 Batch 2800 Loss 6.0371 Accuracy 0.1644\n",
            "Epoch 3 Batch 2900 Loss 6.0384 Accuracy 0.1645\n",
            "Epoch 3 Batch 3000 Loss 6.0394 Accuracy 0.1646\n",
            "Epoch 3 Batch 3100 Loss 6.0409 Accuracy 0.1646\n",
            "Epoch 3 Batch 3200 Loss 6.0431 Accuracy 0.1647\n",
            "Epoch 3 Batch 3300 Loss 6.0437 Accuracy 0.1648\n",
            "Epoch 3 Batch 3400 Loss 6.0457 Accuracy 0.1649\n",
            "Epoch 3 Batch 3500 Loss 6.0466 Accuracy 0.1649\n",
            "Epoch 3 Loss 6.0485 Accuracy 0.1650\n",
            "Time taken for 1 epoch: 1460.1898910999298 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 5.4387 Accuracy 0.1650\n",
            "Epoch 4 Batch 100 Loss 5.8899 Accuracy 0.1651\n",
            "Epoch 4 Batch 200 Loss 5.8955 Accuracy 0.1651\n",
            "Epoch 4 Batch 300 Loss 5.9199 Accuracy 0.1652\n",
            "Epoch 4 Batch 400 Loss 5.9207 Accuracy 0.1653\n",
            "Epoch 4 Batch 500 Loss 5.9288 Accuracy 0.1654\n",
            "Epoch 4 Batch 600 Loss 5.9261 Accuracy 0.1655\n",
            "Epoch 4 Batch 700 Loss 5.9339 Accuracy 0.1655\n",
            "Epoch 4 Batch 800 Loss 5.9411 Accuracy 0.1656\n",
            "Epoch 4 Batch 900 Loss 5.9471 Accuracy 0.1657\n",
            "Epoch 4 Batch 1000 Loss 5.9512 Accuracy 0.1658\n",
            "Epoch 4 Batch 1100 Loss 5.9559 Accuracy 0.1658\n",
            "Epoch 4 Batch 1200 Loss 5.9589 Accuracy 0.1659\n",
            "Epoch 4 Batch 1300 Loss 5.9630 Accuracy 0.1660\n",
            "Epoch 4 Batch 1400 Loss 5.9702 Accuracy 0.1661\n",
            "Epoch 4 Batch 1500 Loss 5.9765 Accuracy 0.1661\n",
            "Epoch 4 Batch 1600 Loss 5.9813 Accuracy 0.1662\n",
            "Epoch 4 Batch 1700 Loss 5.9830 Accuracy 0.1663\n",
            "Epoch 4 Batch 1800 Loss 5.9852 Accuracy 0.1663\n",
            "Epoch 4 Batch 1900 Loss 5.9907 Accuracy 0.1664\n",
            "Epoch 4 Batch 2000 Loss 5.9926 Accuracy 0.1665\n",
            "Epoch 4 Batch 2100 Loss 5.9965 Accuracy 0.1666\n",
            "Epoch 4 Batch 2200 Loss 5.9986 Accuracy 0.1666\n",
            "Epoch 4 Batch 2300 Loss 6.0016 Accuracy 0.1667\n",
            "Epoch 4 Batch 2400 Loss 6.0031 Accuracy 0.1668\n",
            "Epoch 4 Batch 2500 Loss 6.0061 Accuracy 0.1668\n",
            "Epoch 4 Batch 2600 Loss 6.0095 Accuracy 0.1669\n",
            "Epoch 4 Batch 2700 Loss 6.0108 Accuracy 0.1670\n",
            "Epoch 4 Batch 2800 Loss 6.0131 Accuracy 0.1670\n",
            "Epoch 4 Batch 2900 Loss 6.0147 Accuracy 0.1671\n",
            "Epoch 4 Batch 3000 Loss 6.0170 Accuracy 0.1672\n",
            "Epoch 4 Batch 3100 Loss 6.0178 Accuracy 0.1672\n",
            "Epoch 4 Batch 3200 Loss 6.0204 Accuracy 0.1673\n",
            "Epoch 4 Batch 3300 Loss 6.0210 Accuracy 0.1674\n",
            "Epoch 4 Batch 3400 Loss 6.0228 Accuracy 0.1674\n",
            "Epoch 4 Batch 3500 Loss 6.0246 Accuracy 0.1675\n",
            "Epoch 4 Loss 6.0260 Accuracy 0.1675\n",
            "Time taken for 1 epoch: 1459.7367196083069 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 6.1078 Accuracy 0.1675\n",
            "Epoch 5 Batch 100 Loss 5.8951 Accuracy 0.1676\n",
            "Epoch 5 Batch 200 Loss 5.9002 Accuracy 0.1677\n",
            "Epoch 5 Batch 300 Loss 5.9032 Accuracy 0.1678\n",
            "Epoch 5 Batch 400 Loss 5.9184 Accuracy 0.1678\n",
            "Epoch 5 Batch 500 Loss 5.9232 Accuracy 0.1679\n",
            "Epoch 5 Batch 600 Loss 5.9262 Accuracy 0.1680\n",
            "Epoch 5 Batch 700 Loss 5.9279 Accuracy 0.1680\n",
            "Epoch 5 Batch 800 Loss 5.9349 Accuracy 0.1681\n",
            "Epoch 5 Batch 900 Loss 5.9407 Accuracy 0.1682\n",
            "Epoch 5 Batch 1000 Loss 5.9493 Accuracy 0.1682\n",
            "Epoch 5 Batch 1100 Loss 5.9509 Accuracy 0.1683\n",
            "Epoch 5 Batch 1200 Loss 5.9535 Accuracy 0.1684\n",
            "Epoch 5 Batch 1300 Loss 5.9579 Accuracy 0.1684\n",
            "Epoch 5 Batch 1400 Loss 5.9601 Accuracy 0.1685\n",
            "Epoch 5 Batch 1500 Loss 5.9626 Accuracy 0.1686\n",
            "Epoch 5 Batch 1600 Loss 5.9657 Accuracy 0.1686\n",
            "Epoch 5 Batch 1700 Loss 5.9688 Accuracy 0.1687\n",
            "Epoch 5 Batch 1800 Loss 5.9703 Accuracy 0.1688\n",
            "Epoch 5 Batch 1900 Loss 5.9738 Accuracy 0.1688\n",
            "Epoch 5 Batch 2000 Loss 5.9754 Accuracy 0.1689\n",
            "Epoch 5 Batch 2100 Loss 5.9789 Accuracy 0.1690\n",
            "Epoch 5 Batch 2200 Loss 5.9809 Accuracy 0.1690\n",
            "Epoch 5 Batch 2300 Loss 5.9831 Accuracy 0.1691\n",
            "Epoch 5 Batch 2400 Loss 5.9850 Accuracy 0.1692\n",
            "Epoch 5 Batch 2500 Loss 5.9867 Accuracy 0.1692\n",
            "Epoch 5 Batch 2600 Loss 5.9884 Accuracy 0.1693\n",
            "Epoch 5 Batch 2700 Loss 5.9914 Accuracy 0.1694\n",
            "Epoch 5 Batch 2800 Loss 5.9939 Accuracy 0.1694\n",
            "Epoch 5 Batch 2900 Loss 5.9963 Accuracy 0.1695\n",
            "Epoch 5 Batch 3000 Loss 5.9981 Accuracy 0.1695\n",
            "Epoch 5 Batch 3100 Loss 6.0003 Accuracy 0.1696\n",
            "Epoch 5 Batch 3200 Loss 6.0017 Accuracy 0.1697\n",
            "Epoch 5 Batch 3300 Loss 6.0032 Accuracy 0.1697\n",
            "Epoch 5 Batch 3400 Loss 6.0031 Accuracy 0.1698\n",
            "Epoch 5 Batch 3500 Loss 6.0047 Accuracy 0.1698\n",
            "Saving checkpoint for epoch 5 at /content/drive/MyDrive/DL Project/ckpt-3\n",
            "Epoch 5 Loss 6.0056 Accuracy 0.1699\n",
            "Time taken for 1 epoch: 1463.9948225021362 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "j5Qh_3Xx0S2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(input_article):\n",
        "    input_article = article_tokenizer.texts_to_sequences([input_article])\n",
        "    input_article = tf.keras.preprocessing.sequence.pad_sequences(input_article, maxlen=ENCODER_LEN, \n",
        "                                                                   padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_article[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index['<sos>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(DECODER_LEN):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input, \n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index['<eos>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:09:51.132359Z",
          "iopub.execute_input": "2022-04-18T21:09:51.132701Z",
          "iopub.status.idle": "2022-04-18T21:09:51.144071Z",
          "shell.execute_reply.started": "2022-04-18T21:09:51.13267Z",
          "shell.execute_reply": "2022-04-18T21:09:51.143225Z"
        },
        "trusted": true,
        "id": "DMHcFFWy0S2u"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input_article):\n",
        "    summarized = evaluate(input_article=input_article)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  \n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:09:51.931256Z",
          "iopub.execute_input": "2022-04-18T21:09:51.931941Z",
          "iopub.status.idle": "2022-04-18T21:09:51.940607Z",
          "shell.execute_reply.started": "2022-04-18T21:09:51.931899Z",
          "shell.execute_reply": "2022-04-18T21:09:51.93954Z"
        },
        "trusted": true,
        "id": "-K3LUP_10S2v"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions\n",
        "\n",
        "Below me make predictions on some texts to see how the model is performimg. Since this was a very basic approach the model won't perform that well but it can surely be improved."
      ],
      "metadata": {
        "id": "FUOx09ie0S2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Real Headline : \", summary.iloc[16][5:-5],\"\\nPredicted Summary : \", summarize(article.iloc[16]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWR69OGyVCmm",
        "outputId": "283d74e9-2fa3-46b3-f941-1205da36c224"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Headline :   The mother, who cannot be named, pleaded guilty to producing and disseminating child abuse material .\n",
            "Her husband said she should not be imprisoned but instead be allowed back home .\n",
            "She took naked photos of her daughters allegedly at the request of their Sydney dance teacher Grant Davies .\n",
            "Davies ran a studio in Sydney's inner west and trained performers for his productions like Billy Elliot .  \n",
            "Predicted Summary :  the former pm was accused of having sex with her mother in a young girl he was jailed for four years for four years for sex offences the teenager was jailed for four years for the assault\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Real Headline : \", summary.iloc[23][5:-5],\"\\nPredicted Summary : \", summarize(article.iloc[23]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtTJeaOmhhRN",
        "outputId": "af01878c-7220-427e-ac06-74f7d5217f3f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Headline :   The photographs were taken at Namburg National Park by self-taught Perth astrophotographer Michael Goh .\n",
            "He sometimes spends all night out in the elements and they have won the father-of-two a swag of awards .\n",
            "Goh said he was constantly competing with the weather to take the perfect shot, so he always had a camera ready .  \n",
            "Predicted Summary :  the pair were spotted in the northern territory in the northern territory the pair were spotted in the northern territory in the northern territory the pair were spotted in the northern territory in the northern territory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_score = load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "KcVjt-OmwuM0"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {'original_summary':[], 'pred_summary':[]}\n",
        "\n",
        "for i in range(150,161):\n",
        "    dict1['original_summary'].append(summary.iloc[i][5:-5])\n",
        "    dict1['pred_summary'].append(summarize(article.iloc[i]))\n",
        "\n",
        "predicted_df2 = pd.DataFrame.from_dict(dict1)"
      ],
      "metadata": {
        "id": "SxYuVZd39n3S"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df2.to_csv('/content/drive/MyDrive/DL Project/Transformer-predictions.csv', index = False)"
      ],
      "metadata": {
        "id": "-gWwvvWkDfyG"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DL Project/Transformer-predictions.csv')"
      ],
      "metadata": {
        "id": "JoSuI9y_DjfE"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = df['original_summary'].tolist()\n",
        "list2 = df['pred_summary'].tolist()"
      ],
      "metadata": {
        "id": "eagq6OY99pyx"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results2 = metric.compute(predictions=list2, references=list1)"
      ],
      "metadata": {
        "id": "Zb0_mZjw9zTC"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ROUGE 1: \", results2[\"rouge1\"].high.fmeasure)\n",
        "print(\"ROUGE 2: \", results2[\"rouge2\"].high.fmeasure)\n",
        "print(\"ROUGE L: \", results2[\"rougeL\"].high.fmeasure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMBKs1f091nw",
        "outputId": "ecfe6825-bc34-49fd-f6d5-ad4ada273cf8"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE 1:  0.20666091937111847\n",
            "ROUGE 2:  0.01733022827899488\n",
            "ROUGE L:  0.142890160726438\n"
          ]
        }
      ]
    }
  ]
}